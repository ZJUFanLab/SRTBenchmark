{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8554983-c61a-4143-97ce-09d12da7bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, homogeneity_completeness_v_measure, fowlkes_mallows_score, silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361c342-d7ce-463c-85c8-3e5640686d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ARI(groundtruth, cluster):\n",
    "    ari = adjusted_rand_score(groundtruth, cluster)\n",
    "    return ari\n",
    "def calculate_NMI(groundtruth, cluster):\n",
    "    nmi = normalized_mutual_info_score(groundtruth, cluster)\n",
    "    return nmi\n",
    "def calculate_FMI(groundtruth, cluster):\n",
    "    fmi = fowlkes_mallows_score(groundtruth, cluster)\n",
    "    return fmi\n",
    "def calculate_Purity(groundtruth, cluster):\n",
    "    # compute contingency matrix\n",
    "    cm = contingency_matrix(groundtruth, cluster)\n",
    "    return np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
    "def calculate_v_measure(groundtruth, cluster):\n",
    "    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(groundtruth, cluster)\n",
    "    return homogeneity, completeness, v_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e278d48-70b8-41b1-96b0-5575ad2c6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fx_1NN(i,location_in):\n",
    "    location_in = np.array(location_in)\n",
    "    dist_array = distance_matrix(location_in[i,:][None,:],location_in)[0,:]\n",
    "    dist_array[i] = np.inf\n",
    "    return np.min(dist_array)\n",
    "    \n",
    "def fx_kNN(i,location_in,k,cluster_in):\n",
    "    location_in = np.array(location_in)\n",
    "    cluster_in = np.array(cluster_in)\n",
    "    dist_array = distance_matrix(location_in[i,:][None,:],location_in)[0,:]\n",
    "    dist_array[i] = np.inf\n",
    "    ind = np.argsort(dist_array)[:k]\n",
    "    cluster_use = np.array(cluster_in)\n",
    "    if np.sum(cluster_use[ind]!=cluster_in[i])>(k/2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def calculate_PAS(label,location):\n",
    "        \n",
    "    label = np.array(label)\n",
    "    location = np.array(location)\n",
    "    matched_location = location\n",
    "    results = [fx_kNN(i, matched_location, k=10, cluster_in=label) for i in range(matched_location.shape[0])]\n",
    "    return np.sum(results)/len(label)\n",
    "def calculate_CHAOS(label, location):\n",
    "\n",
    "    label = np.array(label)\n",
    "    location = np.array(location)\n",
    "    matched_location = StandardScaler().fit_transform(location)\n",
    "\n",
    "    label_unique = np.unique(label)\n",
    "    dist_val = np.zeros(len(label_unique))\n",
    "    count = 0\n",
    "    for k in label_unique:\n",
    "        location_cluster = matched_location[label==k,:]\n",
    "        if len(location_cluster)<=2:\n",
    "            continue\n",
    "        n_location_cluster = len(location_cluster)\n",
    "        results = [fx_1NN(i,location_cluster) for i in range(n_location_cluster)]\n",
    "        dist_val[count] = np.sum(results)\n",
    "        count = count + 1\n",
    "\n",
    "    return np.sum(dist_val)/len(label)\n",
    "def calculate_ASW(adata, pred_key, spatial_key='spatial'):\n",
    "    d = squareform(pdist(adata.obsm[spatial_key]))\n",
    "    #print(d)\n",
    "    return silhouette_score(X=d, labels=adata.obs[pred_key], metric='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d262ce0-f1ca-4d47-92aa-0b6bf1943dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cluster_matrix(adata, tech, tissue, dataset, sample, method):\n",
    "\n",
    "\n",
    "    gt = adata.obs['ground_truth']\n",
    "    cluster = adata.obs['predicted']\n",
    "          \n",
    "    ari = calculate_ARI(gt, cluster)\n",
    "    nmi = calculate_NMI(gt, cluster)\n",
    "    fmi = calculate_FMI(gt, cluster)\n",
    "    ps = calculate_Purity(gt, cluster)\n",
    "    homogeneity, completeness, v_measure = calculate_v_measure(gt, cluster)\n",
    "    \n",
    "\n",
    "    pas_gt = calculate_PAS(gt, adata.obsm['spatial'])\n",
    "    chaos_gt = calculate_CHAOS(gt, adata.obsm['spatial'])\n",
    "    asw_gt = calculate_ASW(adata, 'ground_truth')\n",
    "\n",
    "    pas_cluster = calculate_PAS(cluster, adata.obsm['spatial'])\n",
    "    chaos_cluster = calculate_CHAOS(cluster, adata.obsm['spatial'])       \n",
    "    asw_cluster = calculate_ASW(adata, key_dic.get('predicted')\n",
    "   \n",
    "    df = pd.DataFrame(columns=[\"Tech\", \"Tissue\", \"Dataset\", \"Sample\", \"Method\", \"ARI\", \"NMI\", \"FMI\", \"Purity\", \"Homogeneity\", \"Completeness\", \"V_measure\", \n",
    "                                     \"pas_gt\", \"pas_cluster\", \"chaos_gt\", \"chaos_cluster\", \"asw_gt\", \"asw_cluster\"])\n",
    "    \n",
    "    df = df._append(pd.Series([tech, tissue, dataset, sample, method, ari, nmi, fmi, ps, homogeneity, completeness, v_measure, \n",
    "                               pas_gt, pas_cluster, chaos_gt, chaos_cluster, asw_gt, asw_cluster],\n",
    "                              index=[\"Tech\", \"Tissue\", \"Dataset\", \"Sample\", \"Method\", \"ARI\", \"NMI\", \"FMI\", \"Purity\", \"Homogeneity\", \"Completeness\", \"V_measure\", \n",
    "                                     \"pas_gt\", \"pas_cluster\", \"chaos_gt\", \"chaos_cluster\", \"asw_gt\", \"asw_cluster\"]), ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9a2fd-210a-48cc-9dce-9474fbc71af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_rank(df, value_column, index_column='Method', columns_column='Tissue'):\n",
    "\n",
    "    median_table = df.pivot_table(values=value_column, index=index_column, columns=columns_column, aggfunc='median')\n",
    "    ranked_table = median_table.rank(ascending=False, method='min').astype(int)\n",
    "    return ranked_table\n",
    "\n",
    "columns_to_calculate = ['ARI', 'NMI', 'FMI', 'Purity', 'Homogeneity', 'Completeness', 'V_measure']\n",
    "ranked_tables = {}\n",
    "for column in columns_to_calculate:\n",
    "    ranked_tables[column] = calculate_and_rank(df_10X, value_column=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbe554-174f-43d5-9094-b9e49d39c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_tables['Accuracy_Score'] = (ranked_tables['ARI'] + ranked_tables['NMI'] + ranked_tables['FMI'] + ranked_tables['Purity'] + ranked_tables['Homogeneity'] + ranked_tables['Completeness']) / 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAGATE_tf",
   "language": "python",
   "name": "stagate_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
